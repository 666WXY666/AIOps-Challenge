{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANM Project trace paths finder",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A27e_mLs3TnV",
        "outputId": "30839a48-f798-4dfa-f07b-072ed45e5bd0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5Udi9bnhwoV"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV78LThJhzGU"
      },
      "source": [
        "import os\n",
        "BASE_DIR = '/content/drive/MyDrive/anmproject/trace.zip (Unzipped Files)/trace/'\n",
        "tracefiles = tuple(filter(lambda x: 'trace_' in x, os.listdir(BASE_DIR)))\n",
        "\n",
        "datasets = [pd.read_csv(BASE_DIR + x) for x in tracefiles]\n",
        " \n",
        "\n",
        "#JDBC and LOCAL both lose dsName, becoming the database as their servicename\n",
        "for i, df in enumerate(datasets):\n",
        "    if df['callType'].iloc[0] == 'JDBC':\n",
        "      df['serviceName'] = df['dsName']\n",
        "      df = df.drop(['dsName'], axis=1)\n",
        "    elif df['callType'].iloc[0] == 'LOCAL':\n",
        "      df = df.drop(['serviceName'], axis=1)\n",
        "      df['serviceName'] = df['dsName']\n",
        "      df = df.drop(['dsName'], axis=1)\n",
        "    datasets[i] = df\n",
        "\n",
        "# concat dfs into 1 df\n",
        "traces = pd.concat(datasets)\n",
        "\n",
        "del datasets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRrgpYBhh3Qq"
      },
      "source": [
        "d = dict(tuple(traces.groupby('traceId')))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlTH69cBo6bv",
        "outputId": "5d1dc467-26b7-4e6a-dfbc-aeb5805a0062"
      },
      "source": [
        "i = 0\n",
        "for trace in d:\n",
        "  if i % 10000 == 0:\n",
        "    print(f'Currently at {i}')\n",
        "  d[trace] = d[trace].sort_values('pid').sort_values('startTime')\n",
        "  i+=1\n",
        "del traces"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently at 0\n",
            "Currently at 10000\n",
            "Currently at 20000\n",
            "Currently at 30000\n",
            "Currently at 40000\n",
            "Currently at 50000\n",
            "Currently at 60000\n",
            "Currently at 70000\n",
            "Currently at 80000\n",
            "Currently at 90000\n",
            "Currently at 100000\n",
            "Currently at 110000\n",
            "Currently at 120000\n",
            "Currently at 130000\n",
            "Currently at 140000\n",
            "Currently at 150000\n",
            "Currently at 160000\n",
            "Currently at 170000\n",
            "Currently at 180000\n",
            "Currently at 190000\n",
            "Currently at 200000\n",
            "Currently at 210000\n",
            "Currently at 220000\n",
            "Currently at 230000\n",
            "Currently at 240000\n",
            "Currently at 250000\n",
            "Currently at 260000\n",
            "Currently at 270000\n",
            "Currently at 280000\n",
            "Currently at 290000\n",
            "Currently at 300000\n",
            "Currently at 310000\n",
            "Currently at 320000\n",
            "Currently at 330000\n",
            "Currently at 340000\n",
            "Currently at 350000\n",
            "Currently at 360000\n",
            "Currently at 370000\n",
            "Currently at 380000\n",
            "Currently at 390000\n",
            "Currently at 400000\n",
            "Currently at 410000\n",
            "Currently at 420000\n",
            "Currently at 430000\n",
            "Currently at 440000\n",
            "Currently at 450000\n",
            "Currently at 460000\n",
            "Currently at 470000\n",
            "Currently at 480000\n",
            "Currently at 490000\n",
            "Currently at 500000\n",
            "Currently at 510000\n",
            "Currently at 520000\n",
            "Currently at 530000\n",
            "Currently at 540000\n",
            "Currently at 550000\n",
            "Currently at 560000\n",
            "Currently at 570000\n",
            "Currently at 580000\n",
            "Currently at 590000\n",
            "Currently at 600000\n",
            "Currently at 610000\n",
            "Currently at 620000\n",
            "Currently at 630000\n",
            "Currently at 640000\n",
            "Currently at 650000\n",
            "Currently at 660000\n",
            "Currently at 670000\n",
            "Currently at 680000\n",
            "Currently at 690000\n",
            "Currently at 700000\n",
            "Currently at 710000\n",
            "Currently at 720000\n",
            "Currently at 730000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvL72VtTjFsF"
      },
      "source": [
        "from itertools import groupby\n",
        "\n",
        "def trace_to_call_path(df):\n",
        "    \"\"\"\n",
        "    df : Trace Pandas dataframe. The dataframe must be sorted and pre processed\n",
        "    Pre processing includes dsName being removed from JDBC and LOCAL\n",
        "    \"\"\"\n",
        "    \n",
        "    # transform CSF serviceName\n",
        "    ids = df[df['callType'] == 'CSF']['id']\n",
        "    children_cmdb = df[df['pid'].isin(ids)]['cmdb_id']\n",
        "    df.loc[df['callType']=='CSF', 'serviceName'] = list(children_cmdb)\n",
        "\n",
        "\n",
        "    names = dict(zip(df.id, df.serviceName))\n",
        "    names['None'] = 'Start'\n",
        "\n",
        "    path = []\n",
        "    durations = []\n",
        "    def merge_fn(row):\n",
        "        \"\"\" Makes a row become (pid, id) format while filtering same service calls\"\"\"\n",
        "        v = (names[row['pid']], names[row['id']])\n",
        "        if v[0] == v[1]:\n",
        "            durations[-1] += row['elapsedTime']\n",
        "            return\n",
        "        else:\n",
        "            durations.append(row['elapsedTime'])\n",
        "        path.append(v)\n",
        "    \n",
        "    df.apply(merge_fn, axis=1) # apply horizontally\n",
        "    l = path\n",
        "    \n",
        "    # reduce repeated duplicates and make sure their times are saved\n",
        "    tmp = [(x[0], sum([1 for _ in x[1]])) for x in groupby(path)]\n",
        "    times = list(map(lambda x: x[1], tmp))\n",
        "    path = list(map(lambda x: x[0], tmp))\n",
        "\n",
        "    call_path = set()\n",
        "    # generate path, last sum is the sum of repeated times\n",
        "    for index, p in enumerate(path):\n",
        "        call_path.add((p[1], tuple(path[:index + 1]), sum(durations[index:times[index] + index])))\n",
        "    return call_path"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr1_YCPv_br-"
      },
      "source": [
        "class TraceAnomaly:\n",
        "  def __init__(self, paths_csv_file):\n",
        "      import csv\n",
        "      with open(paths_csv_file) as f:\n",
        "          reader = csv.reader(f)\n",
        "          # transform second position into a tuple instead of string\n",
        "          data = sorted(list(map(lambda x: (x[0],eval(x[1])), list(reader))))\n",
        "          \n",
        "      # path : position\n",
        "      self.paths = {data[i]: i for i in range(len(data))}\n",
        "\n",
        "\n",
        "  def get_stv(self, dataframe):\n",
        "      \"\"\"dataframe should be a single trace already pre processed\"\"\"\n",
        "      graph = list(trace_to_call_path(dataframe))\n",
        "      \n",
        "      # (s, path, time)\n",
        "      indexes = tuple(map(lambda x: self.paths[x[:2]], graph))\n",
        "\n",
        "      # id : val\n",
        "      return dict(zip(indexes, tuple(map(lambda x: x[2], graph))))\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc7eg5mN_l1D"
      },
      "source": [
        "model = TraceAnomaly('/content/drive/MyDrive/anmproject/trace_list.csv')"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd4KZBILyo-_",
        "outputId": "c9b5f712-311d-4883-d772-8ca72542a7c7"
      },
      "source": [
        "model.get_stv(d[list(d.keys())[0]])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: 336.0,\n",
              " 32: 42.0,\n",
              " 128: 44.0,\n",
              " 442: 61.0,\n",
              " 1306: 7.0,\n",
              " 3910: 11.0,\n",
              " 3911: 24.0,\n",
              " 3912: 74.0,\n",
              " 3913: 26.0,\n",
              " 5726: 9.0,\n",
              " 7490: 88.0,\n",
              " 7581: 338.0,\n",
              " 7727: 44.0,\n",
              " 7728: 54.0,\n",
              " 7729: 9.0,\n",
              " 7730: 18.0,\n",
              " 9288: 5.0,\n",
              " 9290: 380.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xBKqlSkABu-"
      },
      "source": [
        "def work(data, index):\n",
        "  keys = list(d.keys())\n",
        "  print(f'Keys are {len(keys)} long and data is {data}')\n",
        "  for i in data:\n",
        "    key = keys[i]\n",
        "    res[index].append((key, model.get_stv(d[key])))\n",
        "\n",
        "NUM_THREADS = 4\n",
        "data = [range(i, len(d), NUM_THREADS) for i in range(NUM_THREADS)]"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXNsnuUpF1PP",
        "outputId": "d5a5b56a-63c8-4ab9-97b2-0c10653c06c4"
      },
      "source": [
        "import threading\n",
        "res = [[] for _ in range(NUM_THREADS)]\n",
        "print(f'Res is {res}')\n",
        "threads = [threading.Thread(target=work, args=(data[i], i)) for i in range(NUM_THREADS)]\n",
        "for t in threads:\n",
        "  t.start()\n",
        "\n",
        "for t in threads:\n",
        "  t.join()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Res is [[], [], [], []]\n",
            "Keys are 730041 long and data is range(0, 730041, 4)\n",
            "Keys are 730041 long and data is range(1, 730041, 4)\n",
            "Keys are 730041 long and data is range(2, 730041, 4)\n",
            "Keys are 730041 long and data is range(3, 730041, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBGTOCbFKTQH"
      },
      "source": [
        "from functools import reduce\n",
        "import csv\n",
        "\n",
        "res = list(reduce(lambda x,y: x+y, res))\n",
        "with open('/content/drive/MyDrive/anmproject/trace_data.csv', 'w+') as f:\n",
        "  wr = csv.writer(f)\n",
        "  wr.writerows(res)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NnLT4OecGpAQ",
        "outputId": "e2f3074c-8036-47ea-b86a-781716089b60"
      },
      "source": [
        "val = [len(res[i]) for i in range(NUM_THREADS)]\n",
        "f'{val} == {sum(val)}'"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[2, 2, 2, 2] == 8'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    }
  ]
}